{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-06T18:02:58.266103Z","iopub.status.busy":"2024-03-06T18:02:58.265663Z","iopub.status.idle":"2024-03-06T18:02:58.275837Z","shell.execute_reply":"2024-03-06T18:02:58.274494Z","shell.execute_reply.started":"2024-03-06T18:02:58.266069Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.304283Z","iopub.status.busy":"2024-03-06T18:02:58.303698Z","iopub.status.idle":"2024-03-06T18:02:58.310103Z","shell.execute_reply":"2024-03-06T18:02:58.30919Z","shell.execute_reply.started":"2024-03-06T18:02:58.304251Z"},"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mporter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/nltk/__init__.py:146\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjsontags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# PACKAGES\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/nltk/chunk/__init__.py:155\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Natural Language Toolkit: Chunkers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2001-2023 NLTK Project\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# For license information, see LICENSE.TXT\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mClasses and interfaces for identifying non-overlapping linguistic\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mgroups (such as base noun phrases) in unrestricted text.  This task is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m     pattern is valid.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkParserI\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregexp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexpChunkParser, RegexpParser\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    158\u001b[0m     ChunkScore,\n\u001b[1;32m    159\u001b[0m     accuracy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     tree2conlltags,\n\u001b[1;32m    166\u001b[0m )\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/nltk/chunk/api.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkScore\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParserI\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChunkParserI\u001b[39;00m(ParserI):\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    A processing interface for identifying non-overlapping groups in\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    unrestricted text.  Typically, chunk parsers are used to find base\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    will always generate a parse.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/nltk/parse/__init__.py:100\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecursivedescent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     96\u001b[0m     RecursiveDescentParser,\n\u001b[1;32m     97\u001b[0m     SteppingRecursiveDescentParser,\n\u001b[1;32m     98\u001b[0m )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshiftreduce\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShiftReduceParser, SteppingShiftReduceParser\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransitionparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransitionParser\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TestGrammar, extract_test_sentences, load_parser\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviterbi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViterbiParser\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/nltk/parse/transitionparser.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svm\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_svmlight_file\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/svm/__init__.py:14\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# See http://scikit-learn.sourceforge.net/modules/svm.html for complete\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# documentation.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#         of their respective owners.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# License: BSD 3 clause (C) INRIA 2010\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bounds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l1_min_c\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC, SVR, LinearSVC, LinearSVR, NuSVC, NuSVR, OneClassSVM\n\u001b[1;32m     16\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearSVR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_min_c\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m ]\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/svm/_classes.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, OutlierMixin, RegressorMixin, _fit_context\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearClassifierMixin, LinearModel, SparseCoefMixin\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Hidden, Interval, StrOptions\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/linear_model/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARDRegression, BayesianRidge\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     ElasticNet,\n\u001b[1;32m     13\u001b[0m     ElasticNetCV,\n\u001b[1;32m     14\u001b[0m     Lasso,\n\u001b[1;32m     15\u001b[0m     LassoCV,\n\u001b[1;32m     16\u001b[0m     MultiTaskElasticNet,\n\u001b[1;32m     17\u001b[0m     MultiTaskElasticNetCV,\n\u001b[1;32m     18\u001b[0m     MultiTaskLasso,\n\u001b[1;32m     19\u001b[0m     MultiTaskLassoCV,\n\u001b[1;32m     20\u001b[0m     enet_path,\n\u001b[1;32m     21\u001b[0m     lasso_path,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_glm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GammaRegressor, PoissonRegressor, TweedieRegressor\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_huber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuberRegressor\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiOutputMixin, RegressorMixin, _fit_context\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_cv\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch, check_array, check_scalar\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     MetadataRouter,\n\u001b[1;32m     24\u001b[0m     MethodMapping,\n\u001b[1;32m     25\u001b[0m     _raise_for_params,\n\u001b[1;32m     26\u001b[0m     get_routing_for_object,\n\u001b[1;32m     27\u001b[0m )\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/model_selection/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ValidationCurveDisplay\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, ParameterGrid, ParameterSampler, RandomizedSearchCV\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_split\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     BaseCrossValidator,\n\u001b[1;32m      7\u001b[0m     BaseShuffleSplit,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     train_test_split,\n\u001b[1;32m     25\u001b[0m )\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/model_selection/_plot.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_matplotlib_support\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _interval_max_min_ratio, _validate_score_name\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m learning_curve, validation_curve\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_BaseCurveDisplay\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_plot_curve\u001b[39m(\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     13\u001b[0m         x_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m         errorbar_kw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m     ):\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone, is_classifier\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FitFailedWarning, UnsetMetadataPassedError\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_scoring, get_scorer_names\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_multimetric_scoring, _MultimetricScorer\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/metrics/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.metrics` module includes score functions, performance metrics\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mand pairwise metrics and distance computations.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     accuracy_score,\n\u001b[1;32m     10\u001b[0m     balanced_accuracy_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     zero_one_loss,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dist_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistanceMetric\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/metrics/cluster/__init__.py:25\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bicluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m consensus_score\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_supervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     adjusted_mutual_info_score,\n\u001b[1;32m     11\u001b[0m     adjusted_rand_score,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     v_measure_score,\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_unsupervised\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     calinski_harabasz_score,\n\u001b[1;32m     27\u001b[0m     davies_bouldin_score,\n\u001b[1;32m     28\u001b[0m     silhouette_samples,\n\u001b[1;32m     29\u001b[0m     silhouette_score,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjusted_mutual_info_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized_mutual_info_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsensus_score\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m ]\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/metrics/cluster/_unsupervised.py:22\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, check_random_state, check_X_y\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     Interval,\n\u001b[1;32m     19\u001b[0m     StrOptions,\n\u001b[1;32m     20\u001b[0m     validate_params,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _VALID_METRICS, pairwise_distances, pairwise_distances_chunked\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_number_of_labels\u001b[39m(n_labels, n_samples):\n\u001b[1;32m     26\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that number of labels are valid.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        Number of samples.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _num_samples, check_non_negative\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pairwise_distances_reduction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArgKmin\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pairwise_fast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _chi2_kernel_fast, _sparse_manhattan\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Utility Functions\u001b[39;00m\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/__init__.py:94\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Pairwise Distances Reductions\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m#    (see :class:`MiddleTermComputer{32,64}`).\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dispatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     95\u001b[0m     ArgKmin,\n\u001b[1;32m     96\u001b[0m     ArgKminClassMode,\n\u001b[1;32m     97\u001b[0m     BaseDistancesReductionDispatcher,\n\u001b[1;32m     98\u001b[0m     RadiusNeighbors,\n\u001b[1;32m     99\u001b[0m     RadiusNeighborsClassMode,\n\u001b[1;32m    100\u001b[0m     sqeuclidean_row_norms,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseDistancesReductionDispatcher\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgKmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqeuclidean_row_norms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    110\u001b[0m ]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# ruff: noqa: E501\u001b[39;00m\n","File \u001b[0;32m/opt/miniconda3/envs/warnify_ml/lib/python3.9/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:17\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dist_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     BOOL_METRICS,\n\u001b[1;32m     10\u001b[0m     METRIC_MAPPING64,\n\u001b[1;32m     11\u001b[0m     DistanceMetric,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_argkmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     ArgKmin32,\n\u001b[1;32m     15\u001b[0m     ArgKmin64,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_argkmin_classmode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     ArgKminClassMode32,\n\u001b[1;32m     19\u001b[0m     ArgKminClassMode64,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _sqeuclidean_row_norms32, _sqeuclidean_row_norms64\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_radius_neighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     RadiusNeighbors32,\n\u001b[1;32m     24\u001b[0m     RadiusNeighbors64,\n\u001b[1;32m     25\u001b[0m )\n","File \u001b[0;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import matplotlib.pyplot as plt\n","import nltk\n","import seaborn as sns\n","from nltk.stem.porter import PorterStemmer\n","from nltk.corpus import stopwords\n","import string\n","from wordcloud import WordCloud\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.345467Z","iopub.status.busy":"2024-03-06T18:02:58.344873Z","iopub.status.idle":"2024-03-06T18:02:58.371443Z","shell.execute_reply":"2024-03-06T18:02:58.370641Z","shell.execute_reply.started":"2024-03-06T18:02:58.345435Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/../data/raw/spam.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["df = pd.read_csv('/../data/raw/spam.csv', encoding='latin1')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.380168Z","iopub.status.busy":"2024-03-06T18:02:58.379554Z","iopub.status.idle":"2024-03-06T18:02:58.387476Z","shell.execute_reply":"2024-03-06T18:02:58.385862Z","shell.execute_reply.started":"2024-03-06T18:02:58.380136Z"},"trusted":true},"outputs":[],"source":["#There are 5572 Messages\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.411466Z","iopub.status.busy":"2024-03-06T18:02:58.411061Z","iopub.status.idle":"2024-03-06T18:02:58.415671Z","shell.execute_reply":"2024-03-06T18:02:58.414836Z","shell.execute_reply.started":"2024-03-06T18:02:58.411432Z"},"trusted":true},"outputs":[],"source":["#1 Data Cleaning\n","#2 EDA\n","#3 Text Preprocessing\n","#4 Model building\n","#5 Evaluation\n","#6 Improvement"]},{"cell_type":"markdown","metadata":{},"source":["# Data Cleaning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.447522Z","iopub.status.busy":"2024-03-06T18:02:58.44679Z","iopub.status.idle":"2024-03-06T18:02:58.461311Z","shell.execute_reply":"2024-03-06T18:02:58.460102Z","shell.execute_reply.started":"2024-03-06T18:02:58.447486Z"},"trusted":true},"outputs":[],"source":["df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.483183Z","iopub.status.busy":"2024-03-06T18:02:58.482785Z","iopub.status.idle":"2024-03-06T18:02:58.49532Z","shell.execute_reply":"2024-03-06T18:02:58.494377Z","shell.execute_reply.started":"2024-03-06T18:02:58.483147Z"},"trusted":true},"outputs":[],"source":["# drop the 3 columns \n","df = df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.524694Z","iopub.status.busy":"2024-03-06T18:02:58.522372Z","iopub.status.idle":"2024-03-06T18:02:58.538412Z","shell.execute_reply":"2024-03-06T18:02:58.536496Z","shell.execute_reply.started":"2024-03-06T18:02:58.524637Z"},"trusted":true},"outputs":[],"source":["#Renaming Columns\n","df = df.rename({'v1': 'target', 'v2': 'text'}, axis =1)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.575416Z","iopub.status.busy":"2024-03-06T18:02:58.575036Z","iopub.status.idle":"2024-03-06T18:02:58.589037Z","shell.execute_reply":"2024-03-06T18:02:58.58782Z","shell.execute_reply.started":"2024-03-06T18:02:58.575386Z"},"trusted":true},"outputs":[],"source":["def le(col):\n","    labelencoder = LabelEncoder()\n","    col = labelencoder.fit_transform(col)\n","    return col\n","df['target'] = le(df['target'])\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.658175Z","iopub.status.busy":"2024-03-06T18:02:58.657801Z","iopub.status.idle":"2024-03-06T18:02:58.669306Z","shell.execute_reply":"2024-03-06T18:02:58.667715Z","shell.execute_reply.started":"2024-03-06T18:02:58.658145Z"},"trusted":true},"outputs":[],"source":["#missing Values\n","df.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.691442Z","iopub.status.busy":"2024-03-06T18:02:58.691048Z","iopub.status.idle":"2024-03-06T18:02:58.703132Z","shell.execute_reply":"2024-03-06T18:02:58.70193Z","shell.execute_reply.started":"2024-03-06T18:02:58.691411Z"},"trusted":true},"outputs":[],"source":["df.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.722639Z","iopub.status.busy":"2024-03-06T18:02:58.722095Z","iopub.status.idle":"2024-03-06T18:02:58.743109Z","shell.execute_reply":"2024-03-06T18:02:58.74185Z","shell.execute_reply.started":"2024-03-06T18:02:58.722575Z"},"trusted":true},"outputs":[],"source":["df = df.drop_duplicates(keep = 'first')\n","df.duplicated().sum()"]},{"cell_type":"markdown","metadata":{},"source":["# EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.749587Z","iopub.status.busy":"2024-03-06T18:02:58.748793Z","iopub.status.idle":"2024-03-06T18:02:58.75761Z","shell.execute_reply":"2024-03-06T18:02:58.756719Z","shell.execute_reply.started":"2024-03-06T18:02:58.74954Z"},"trusted":true},"outputs":[],"source":["df['target'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.778945Z","iopub.status.busy":"2024-03-06T18:02:58.778491Z","iopub.status.idle":"2024-03-06T18:02:58.922106Z","shell.execute_reply":"2024-03-06T18:02:58.920398Z","shell.execute_reply.started":"2024-03-06T18:02:58.778908Z"},"trusted":true},"outputs":[],"source":["#data is imbalance\n","plt.pie(df['target'].value_counts(), labels = ['ham', 'spam'], autopct = '%0.2f')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.926394Z","iopub.status.busy":"2024-03-06T18:02:58.925077Z","iopub.status.idle":"2024-03-06T18:02:58.96079Z","shell.execute_reply":"2024-03-06T18:02:58.958885Z","shell.execute_reply.started":"2024-03-06T18:02:58.926334Z"},"trusted":true},"outputs":[],"source":["#Lets now get word count sentence count and character count\n","df['num_char'] =df['text'].apply(len)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:02:58.965166Z","iopub.status.busy":"2024-03-06T18:02:58.964091Z","iopub.status.idle":"2024-03-06T18:03:00.866852Z","shell.execute_reply":"2024-03-06T18:03:00.86569Z","shell.execute_reply.started":"2024-03-06T18:02:58.965103Z"},"trusted":true},"outputs":[],"source":["#num of words\n","df['num_words']= df['text'].apply(lambda x:len(nltk.word_tokenize(x)))\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:00.870232Z","iopub.status.busy":"2024-03-06T18:03:00.869775Z","iopub.status.idle":"2024-03-06T18:03:01.30756Z","shell.execute_reply":"2024-03-06T18:03:01.306311Z","shell.execute_reply.started":"2024-03-06T18:03:00.8702Z"},"trusted":true},"outputs":[],"source":["#num of sentences\n","df['num_sentences']= df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:01.309465Z","iopub.status.busy":"2024-03-06T18:03:01.30914Z","iopub.status.idle":"2024-03-06T18:03:01.332384Z","shell.execute_reply":"2024-03-06T18:03:01.331249Z","shell.execute_reply.started":"2024-03-06T18:03:01.309437Z"},"trusted":true},"outputs":[],"source":["df[['num_char', 'num_words', 'num_sentences']].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:01.334277Z","iopub.status.busy":"2024-03-06T18:03:01.333574Z","iopub.status.idle":"2024-03-06T18:03:01.355958Z","shell.execute_reply":"2024-03-06T18:03:01.355012Z","shell.execute_reply.started":"2024-03-06T18:03:01.334245Z"},"trusted":true},"outputs":[],"source":["#ham\n","df[df['target'] == 0][['num_char', 'num_words', 'num_sentences']].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:01.357211Z","iopub.status.busy":"2024-03-06T18:03:01.356907Z","iopub.status.idle":"2024-03-06T18:03:01.380639Z","shell.execute_reply":"2024-03-06T18:03:01.379343Z","shell.execute_reply.started":"2024-03-06T18:03:01.357184Z"},"trusted":true},"outputs":[],"source":["#spam\n","df[df['target'] == 1][['num_char', 'num_words', 'num_sentences']].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:01.382454Z","iopub.status.busy":"2024-03-06T18:03:01.381994Z","iopub.status.idle":"2024-03-06T18:03:01.949657Z","shell.execute_reply":"2024-03-06T18:03:01.948406Z","shell.execute_reply.started":"2024-03-06T18:03:01.382407Z"},"trusted":true},"outputs":[],"source":["#for ham messages the average number of characters are less compared to spam\n","plt.figure(figsize=(12,6))\n","sns.histplot(df[df['target'] == 0]['num_char']) #ham\n","sns.histplot(df[df['target'] == 1]['num_char'], color = 'red')#spam\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:01.951426Z","iopub.status.busy":"2024-03-06T18:03:01.951104Z","iopub.status.idle":"2024-03-06T18:03:02.516742Z","shell.execute_reply":"2024-03-06T18:03:02.515545Z","shell.execute_reply.started":"2024-03-06T18:03:01.951396Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","sns.histplot(df[df['target'] == 0]['num_words']) #ham\n","sns.histplot(df[df['target'] == 1]['num_words'], color = 'red')#spam\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:02.522888Z","iopub.status.busy":"2024-03-06T18:03:02.521819Z","iopub.status.idle":"2024-03-06T18:03:03.560515Z","shell.execute_reply":"2024-03-06T18:03:03.559324Z","shell.execute_reply.started":"2024-03-06T18:03:02.522842Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12,6))\n","sns.histplot(df[df['target'] == 0]['num_sentences']) #ham\n","sns.histplot(df[df['target'] == 1]['num_sentences'], color = 'red')#spam\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:03.563063Z","iopub.status.busy":"2024-03-06T18:03:03.562324Z","iopub.status.idle":"2024-03-06T18:03:10.752997Z","shell.execute_reply":"2024-03-06T18:03:10.751705Z","shell.execute_reply.started":"2024-03-06T18:03:03.563021Z"},"trusted":true},"outputs":[],"source":["sns.pairplot(df, hue = 'target')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:10.754831Z","iopub.status.busy":"2024-03-06T18:03:10.75445Z","iopub.status.idle":"2024-03-06T18:03:11.176403Z","shell.execute_reply":"2024-03-06T18:03:11.175195Z","shell.execute_reply.started":"2024-03-06T18:03:10.754799Z"},"trusted":true},"outputs":[],"source":["#coorelation\n","#There is high co-relation between features arounf 0.63 to 0.97 so we will consider onlu one feature\n","#We can choose num  characters becuase it has more variation with target compared to others\n","sns.heatmap(df[['target', 'num_char', 'num_words', 'num_sentences']].corr(), annot = True)"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preprocessing\n","- Lower case\n","- Tokenization: it divides the sentence into words\n","- Removing special characters\n","- removing stopwords and punctuation\n","- stemming"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.178475Z","iopub.status.busy":"2024-03-06T18:03:11.178044Z","iopub.status.idle":"2024-03-06T18:03:11.186334Z","shell.execute_reply":"2024-03-06T18:03:11.185148Z","shell.execute_reply.started":"2024-03-06T18:03:11.178433Z"},"trusted":true},"outputs":[],"source":["# to convert text into lower case \n","txt = 'HELLO HOW ARE YOU PRIYANSHU? Hope you doing fine! I like to do machine Learning%'\n","txt = txt.lower()\n","txt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.18901Z","iopub.status.busy":"2024-03-06T18:03:11.188538Z","iopub.status.idle":"2024-03-06T18:03:11.204253Z","shell.execute_reply":"2024-03-06T18:03:11.20287Z","shell.execute_reply.started":"2024-03-06T18:03:11.188961Z"},"trusted":true},"outputs":[],"source":["#Tokeniztion divides sentence into list\n","txt = nltk.word_tokenize(txt)\n","txt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.206932Z","iopub.status.busy":"2024-03-06T18:03:11.20637Z","iopub.status.idle":"2024-03-06T18:03:11.21686Z","shell.execute_reply":"2024-03-06T18:03:11.215708Z","shell.execute_reply.started":"2024-03-06T18:03:11.20689Z"},"trusted":true},"outputs":[],"source":["## removing Special Characters this keeps only the alphabets and numeric \n","x = []\n","for i in txt:\n","    if i.isalnum():\n","        x.append(i)\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.218908Z","iopub.status.busy":"2024-03-06T18:03:11.218516Z","iopub.status.idle":"2024-03-06T18:03:11.233667Z","shell.execute_reply":"2024-03-06T18:03:11.232485Z","shell.execute_reply.started":"2024-03-06T18:03:11.218878Z"},"trusted":true},"outputs":[],"source":["# remove stopwords and punctuation:\n","txt = x[:]  #so list are immutable \n","x.clear()\n","for i in txt:\n","    if i not in stopwords.words('english') and i not in string.punctuation:\n","        x.append(i)\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.235335Z","iopub.status.busy":"2024-03-06T18:03:11.234988Z","iopub.status.idle":"2024-03-06T18:03:11.245749Z","shell.execute_reply":"2024-03-06T18:03:11.244467Z","shell.execute_reply.started":"2024-03-06T18:03:11.235305Z"},"trusted":true},"outputs":[],"source":["#Stemming makes dancer, dancing to danc\n","txt = x[:]\n","x.clear()\n","for i in txt:\n","    ps = PorterStemmer()\n","    i = ps.stem(i)\n","    x.append(i)\n","x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.247702Z","iopub.status.busy":"2024-03-06T18:03:11.247158Z","iopub.status.idle":"2024-03-06T18:03:11.256407Z","shell.execute_reply":"2024-03-06T18:03:11.255126Z","shell.execute_reply.started":"2024-03-06T18:03:11.247663Z"},"trusted":true},"outputs":[],"source":["#Lets Create the Function\n","def tranform_text(text):\n","    text = text.lower()  #lower case\n","    text = nltk.word_tokenize(text)  # tokenization\n","    \n","    # removing Special Characters\n","    y = []\n","    for i in text:\n","        if i.isalnum():\n","            y.append(i)\n","    text = y[:]\n","    y.clear()\n","    \n","    # remove stopwords and punctuation:\n","    for i in text:\n","        if i not in stopwords.words('english') and i not in string.punctuation:\n","            y.append(i)\n","    text = y[:]\n","    y.clear()\n","    \n","    #Stemming\n","    for i in text:\n","        ps = PorterStemmer()\n","        y.append(ps.stem(i))\n","    return \" \".join(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.258048Z","iopub.status.busy":"2024-03-06T18:03:11.25773Z","iopub.status.idle":"2024-03-06T18:03:11.275477Z","shell.execute_reply":"2024-03-06T18:03:11.274517Z","shell.execute_reply.started":"2024-03-06T18:03:11.258022Z"},"trusted":true},"outputs":[],"source":["tranform_text('HELLO HOW ARE YOU PRIYANSHU? Hope you doing fine! I like to do machine Learning%')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:11.278177Z","iopub.status.busy":"2024-03-06T18:03:11.277222Z","iopub.status.idle":"2024-03-06T18:03:26.844406Z","shell.execute_reply":"2024-03-06T18:03:26.842972Z","shell.execute_reply.started":"2024-03-06T18:03:11.278136Z"},"trusted":true},"outputs":[],"source":["df['tranformed_text'] = df['text'].apply(tranform_text)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:26.846149Z","iopub.status.busy":"2024-03-06T18:03:26.845782Z","iopub.status.idle":"2024-03-06T18:03:27.915129Z","shell.execute_reply":"2024-03-06T18:03:27.913803Z","shell.execute_reply.started":"2024-03-06T18:03:26.846117Z"},"trusted":true},"outputs":[],"source":["# Word cloud of spam messages it shows the important words in text\n","wc = WordCloud(width = 500, height=500, min_font_size=10, background_color = 'white')\n","spam_wordcloud = wc.generate(df[df['target'] ==1]['tranformed_text'].str.cat(sep=\" \"))\n","plt.imshow(spam_wordcloud)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:27.917199Z","iopub.status.busy":"2024-03-06T18:03:27.916848Z","iopub.status.idle":"2024-03-06T18:03:29.549952Z","shell.execute_reply":"2024-03-06T18:03:29.548829Z","shell.execute_reply.started":"2024-03-06T18:03:27.917168Z"},"trusted":true},"outputs":[],"source":["# Word cloud of ham messages it shows the important words in text\n","wc = WordCloud(width = 500, height=500, min_font_size=10, background_color = 'white')\n","ham_wordcloud = wc.generate(df[df['target'] ==0]['tranformed_text'].str.cat(sep=\" \"))\n","plt.imshow(ham_wordcloud)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:29.55244Z","iopub.status.busy":"2024-03-06T18:03:29.551445Z","iopub.status.idle":"2024-03-06T18:03:29.564848Z","shell.execute_reply":"2024-03-06T18:03:29.563712Z","shell.execute_reply.started":"2024-03-06T18:03:29.552408Z"},"trusted":true},"outputs":[],"source":["#lets get top 30 words in sapm messages\n","spam_corpus = []\n","for msg in df[df['target']==1]['tranformed_text'].tolist():\n","    for word in msg.split():\n","        spam_corpus.append(word)\n","len(spam_corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:29.566692Z","iopub.status.busy":"2024-03-06T18:03:29.566321Z","iopub.status.idle":"2024-03-06T18:03:29.588914Z","shell.execute_reply":"2024-03-06T18:03:29.587614Z","shell.execute_reply.started":"2024-03-06T18:03:29.566659Z"},"trusted":true},"outputs":[],"source":["#this are top 30 words in spam\n","from collections import Counter\n","df_spam = pd.DataFrame(Counter(spam_corpus).most_common(30), columns=['Word', 'Frequency'])\n","df_spam"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:29.591122Z","iopub.status.busy":"2024-03-06T18:03:29.590568Z","iopub.status.idle":"2024-03-06T18:03:30.275123Z","shell.execute_reply":"2024-03-06T18:03:30.273921Z","shell.execute_reply.started":"2024-03-06T18:03:29.59109Z"},"trusted":true},"outputs":[],"source":["sns.barplot(x='Word', y='Frequency', data=df_spam)\n","plt.xticks(rotation = 'vertical')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:30.276805Z","iopub.status.busy":"2024-03-06T18:03:30.276439Z","iopub.status.idle":"2024-03-06T18:03:30.301366Z","shell.execute_reply":"2024-03-06T18:03:30.299906Z","shell.execute_reply.started":"2024-03-06T18:03:30.276775Z"},"trusted":true},"outputs":[],"source":["#lets get top 30 words in ham messages now\n","ham_corpus = []\n","for msg in df[df['target']==0]['tranformed_text'].tolist():\n","    for word in msg.split():\n","        ham_corpus.append(word)\n","len(ham_corpus)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:30.303733Z","iopub.status.busy":"2024-03-06T18:03:30.303187Z","iopub.status.idle":"2024-03-06T18:03:30.82577Z","shell.execute_reply":"2024-03-06T18:03:30.824835Z","shell.execute_reply.started":"2024-03-06T18:03:30.303688Z"},"trusted":true},"outputs":[],"source":["#this are top 30 words in ham\n","from collections import Counter\n","df_ham = pd.DataFrame(Counter(ham_corpus).most_common(30), columns=['Word', 'Frequency'])\n","sns.barplot(x='Word', y='Frequency', data=df_ham)\n","plt.xticks(rotation = 'vertical')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Model Building"]},{"cell_type":"markdown","metadata":{},"source":["## Navie Bayes Model"]},{"cell_type":"markdown","metadata":{},"source":["### Using Bag of Words"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:30.833871Z","iopub.status.busy":"2024-03-06T18:03:30.832982Z","iopub.status.idle":"2024-03-06T18:03:30.8391Z","shell.execute_reply":"2024-03-06T18:03:30.837999Z","shell.execute_reply.started":"2024-03-06T18:03:30.833837Z"},"trusted":true},"outputs":[],"source":["#Our Featrure is in Text we need numerical features to train model we would do this by vectorization technique we will use bag of words\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n","cv = CountVectorizer()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:30.840651Z","iopub.status.busy":"2024-03-06T18:03:30.840303Z","iopub.status.idle":"2024-03-06T18:03:30.858795Z","shell.execute_reply":"2024-03-06T18:03:30.857899Z","shell.execute_reply.started":"2024-03-06T18:03:30.840622Z"},"trusted":true},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:30.861291Z","iopub.status.busy":"2024-03-06T18:03:30.860183Z","iopub.status.idle":"2024-03-06T18:03:31.057222Z","shell.execute_reply":"2024-03-06T18:03:31.055877Z","shell.execute_reply.started":"2024-03-06T18:03:30.861246Z"},"trusted":true},"outputs":[],"source":["X_cv = cv.fit_transform(df['tranformed_text']).toarray() #we convert into array cause we get the output in sparse array\n","X_cv"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:31.059304Z","iopub.status.busy":"2024-03-06T18:03:31.058844Z","iopub.status.idle":"2024-03-06T18:03:31.067781Z","shell.execute_reply":"2024-03-06T18:03:31.066415Z","shell.execute_reply.started":"2024-03-06T18:03:31.059263Z"},"trusted":true},"outputs":[],"source":["X_cv.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:31.069446Z","iopub.status.busy":"2024-03-06T18:03:31.069109Z","iopub.status.idle":"2024-03-06T18:03:31.08081Z","shell.execute_reply":"2024-03-06T18:03:31.079483Z","shell.execute_reply.started":"2024-03-06T18:03:31.069417Z"},"trusted":true},"outputs":[],"source":["y = df['target'].values\n","y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:31.082897Z","iopub.status.busy":"2024-03-06T18:03:31.082457Z","iopub.status.idle":"2024-03-06T18:03:31.267536Z","shell.execute_reply":"2024-03-06T18:03:31.266329Z","shell.execute_reply.started":"2024-03-06T18:03:31.082861Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test= train_test_split(X_cv, y, test_size =0.2, random_state = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:31.271019Z","iopub.status.busy":"2024-03-06T18:03:31.270517Z","iopub.status.idle":"2024-03-06T18:03:31.277246Z","shell.execute_reply":"2024-03-06T18:03:31.27605Z","shell.execute_reply.started":"2024-03-06T18:03:31.270973Z"},"trusted":true},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score  \n","gnb = GaussianNB()\n","mnb = MultinomialNB()\n","bnb = BernoulliNB()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:31.280185Z","iopub.status.busy":"2024-03-06T18:03:31.278538Z","iopub.status.idle":"2024-03-06T18:03:31.95925Z","shell.execute_reply":"2024-03-06T18:03:31.958064Z","shell.execute_reply.started":"2024-03-06T18:03:31.280138Z"},"trusted":true},"outputs":[],"source":["gnb.fit(X_train, y_train)\n","y_pred1 = gnb.predict(X_test)\n","print(\"accuracy Score: \", accuracy_score(y_test, y_pred1))\n","print()\n","print(\"confusion matrix: \")\n","print(confusion_matrix(y_test, y_pred1))\n","print()\n","print(\"precision score: \", precision_score(y_test, y_pred1))\n","#In this problem statement precision score is very importatant so it able to classify properly in this true positive"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:31.961361Z","iopub.status.busy":"2024-03-06T18:03:31.96101Z","iopub.status.idle":"2024-03-06T18:03:32.32725Z","shell.execute_reply":"2024-03-06T18:03:32.325704Z","shell.execute_reply.started":"2024-03-06T18:03:31.96133Z"},"trusted":true},"outputs":[],"source":["mnb.fit(X_train, y_train)\n","y_pred2 = mnb.predict(X_test)\n","print(\"accuracy Score: \", accuracy_score(y_test, y_pred2))\n","print()\n","print(\"confusion matrix: \")\n","print(confusion_matrix(y_test, y_pred2))\n","print()\n","print(\"precision score: \", precision_score(y_test, y_pred2))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:32.330331Z","iopub.status.busy":"2024-03-06T18:03:32.329413Z","iopub.status.idle":"2024-03-06T18:03:32.932212Z","shell.execute_reply":"2024-03-06T18:03:32.930706Z","shell.execute_reply.started":"2024-03-06T18:03:32.330268Z"},"trusted":true},"outputs":[],"source":["bnb.fit(X_train, y_train)\n","y_pred3 = bnb.predict(X_test)\n","print(\"accuracy Score: \", accuracy_score(y_test, y_pred3))\n","print()\n","print(\"confusion matrix: \")\n","print(confusion_matrix(y_test, y_pred3))\n","print()\n","print(\"precision score: \", precision_score(y_test, y_pred3))"]},{"cell_type":"markdown","metadata":{},"source":["### Using Tfidf Vectorizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:32.935205Z","iopub.status.busy":"2024-03-06T18:03:32.934338Z","iopub.status.idle":"2024-03-06T18:03:33.26191Z","shell.execute_reply":"2024-03-06T18:03:33.260792Z","shell.execute_reply.started":"2024-03-06T18:03:32.935142Z"},"trusted":true},"outputs":[],"source":["tfidf = TfidfVectorizer()\n","X_tf = tfidf.fit_transform(df['tranformed_text']).toarray() #we convert into array cause we get the output in sparse array\n","X_tf"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:33.264331Z","iopub.status.busy":"2024-03-06T18:03:33.263637Z","iopub.status.idle":"2024-03-06T18:03:33.423243Z","shell.execute_reply":"2024-03-06T18:03:33.42205Z","shell.execute_reply.started":"2024-03-06T18:03:33.26429Z"},"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test= train_test_split(X_tf, y, test_size =0.2, random_state = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:33.425617Z","iopub.status.busy":"2024-03-06T18:03:33.425118Z","iopub.status.idle":"2024-03-06T18:03:33.986907Z","shell.execute_reply":"2024-03-06T18:03:33.985678Z","shell.execute_reply.started":"2024-03-06T18:03:33.42555Z"},"trusted":true},"outputs":[],"source":["gnb.fit(X_train, y_train)\n","y_pred1 = gnb.predict(X_test)\n","print(\"accuracy Score: \", accuracy_score(y_test, y_pred1))\n","print()\n","print(\"confusion matrix: \")\n","print(confusion_matrix(y_test, y_pred1))\n","print()\n","print(\"precision score: \", precision_score(y_test, y_pred1))\n","#In this problem statement precision score is very importatant so it able to classify properly in this false positive"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:33.988536Z","iopub.status.busy":"2024-03-06T18:03:33.988208Z","iopub.status.idle":"2024-03-06T18:03:34.098735Z","shell.execute_reply":"2024-03-06T18:03:34.097544Z","shell.execute_reply.started":"2024-03-06T18:03:33.98851Z"},"trusted":true},"outputs":[],"source":["mnb.fit(X_train, y_train)\n","y_pred2 = mnb.predict(X_test)\n","print(\"accuracy Score: \", accuracy_score(y_test, y_pred2))\n","print()\n","print(\"confusion matrix: \")\n","print(confusion_matrix(y_test, y_pred2))\n","print()\n","print(\"precision score: \", precision_score(y_test, y_pred2))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:34.101147Z","iopub.status.busy":"2024-03-06T18:03:34.100427Z","iopub.status.idle":"2024-03-06T18:03:34.489102Z","shell.execute_reply":"2024-03-06T18:03:34.487591Z","shell.execute_reply.started":"2024-03-06T18:03:34.101108Z"},"trusted":true},"outputs":[],"source":["bnb.fit(X_train, y_train)\n","y_pred3 = bnb.predict(X_test)\n","print(\"accuracy Score: \", accuracy_score(y_test, y_pred3))\n","print()\n","print(\"confusion matrix: \")\n","print(confusion_matrix(y_test, y_pred3))\n","print()\n","print(\"precision score: \", precision_score(y_test, y_pred3))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:34.492472Z","iopub.status.busy":"2024-03-06T18:03:34.491486Z","iopub.status.idle":"2024-03-06T18:03:34.501568Z","shell.execute_reply":"2024-03-06T18:03:34.499794Z","shell.execute_reply.started":"2024-03-06T18:03:34.492412Z"},"trusted":true},"outputs":[],"source":["#we choosed tfidf  --> mnb   we choosed the multinomial classifier because its precision score is best beacuse its predicting false postive(spam and predicting right)"]},{"cell_type":"markdown","metadata":{},"source":["## Other Models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:34.507287Z","iopub.status.busy":"2024-03-06T18:03:34.504885Z","iopub.status.idle":"2024-03-06T18:03:34.525352Z","shell.execute_reply":"2024-03-06T18:03:34.523694Z","shell.execute_reply.started":"2024-03-06T18:03:34.507209Z"},"trusted":true},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from xgboost import XGBClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:34.537798Z","iopub.status.busy":"2024-03-06T18:03:34.533403Z","iopub.status.idle":"2024-03-06T18:03:34.558664Z","shell.execute_reply":"2024-03-06T18:03:34.556355Z","shell.execute_reply.started":"2024-03-06T18:03:34.537728Z"},"trusted":true},"outputs":[],"source":["svc = SVC(kernel='sigmoid', gamma=1.0)\n","knc = KNeighborsClassifier()\n","mnb = MultinomialNB()\n","dtc = DecisionTreeClassifier(max_depth=5)\n","lrc = LogisticRegression(solver='liblinear', penalty='l1')\n","rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n","abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n","#bc = BaggingClassifier(n_estimators=50, random_state=2)\n","etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n","gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n","xgb = XGBClassifier(n_estimators=50,random_state=2)\n","\n","clfs = {\n","    'SVC' : svc,\n","    'KN' : knc, \n","    'NB': mnb, \n","    'DT': dtc, \n","    'LR': lrc, \n","    'RF': rfc, \n","    'AdaBoost': abc, \n","    'ETC': etc,\n","    'GBDT':gbdt,\n","    'xgb':xgb\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:34.571139Z","iopub.status.busy":"2024-03-06T18:03:34.566696Z","iopub.status.idle":"2024-03-06T18:03:34.58422Z","shell.execute_reply":"2024-03-06T18:03:34.582839Z","shell.execute_reply.started":"2024-03-06T18:03:34.571065Z"},"trusted":true},"outputs":[],"source":["def train_classifier(clf,X_train,y_train,X_test,y_test):\n","    clf.fit(X_train,y_train)\n","    y_pred = clf.predict(X_test)\n","    accuracy = accuracy_score(y_test,y_pred)\n","    precision = precision_score(y_test,y_pred)\n","    \n","    return accuracy,precision"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:34.592675Z","iopub.status.busy":"2024-03-06T18:03:34.591918Z","iopub.status.idle":"2024-03-06T18:03:43.621381Z","shell.execute_reply":"2024-03-06T18:03:43.620038Z","shell.execute_reply.started":"2024-03-06T18:03:34.592617Z"},"trusted":true},"outputs":[],"source":["tfidf = TfidfVectorizer(max_features = 3000) #our model is giving best accuracy for 3000 features and the precision stays 1\n","X_tf = tfidf.fit_transform(df['tranformed_text']).toarray() #we convert into array cause we get the output in sparse array\n","X_train, X_test, y_train, y_test= train_test_split(X_tf, y, test_size =0.2, random_state = 2)\n","train_classifier(svc,X_train,y_train,X_test,y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:03:43.623677Z","iopub.status.busy":"2024-03-06T18:03:43.623229Z","iopub.status.idle":"2024-03-06T18:04:51.673693Z","shell.execute_reply":"2024-03-06T18:04:51.672669Z","shell.execute_reply.started":"2024-03-06T18:03:43.623638Z"},"trusted":true},"outputs":[],"source":["accuracy_scores = []\n","precision_scores = []\n","\n","for name,clf in clfs.items():\n","    \n","    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n","    \n","    print(\"For \",name)\n","    print(\"Accuracy - \",current_accuracy)\n","    print(\"Precision - \",current_precision)\n","    \n","    accuracy_scores.append(current_accuracy)\n","    precision_scores.append(current_precision)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:51.680653Z","iopub.status.busy":"2024-03-06T18:04:51.678208Z","iopub.status.idle":"2024-03-06T18:04:51.698238Z","shell.execute_reply":"2024-03-06T18:04:51.697192Z","shell.execute_reply.started":"2024-03-06T18:04:51.680592Z"},"trusted":true},"outputs":[],"source":["performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)\n","performance_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:51.700326Z","iopub.status.busy":"2024-03-06T18:04:51.699799Z","iopub.status.idle":"2024-03-06T18:04:51.719019Z","shell.execute_reply":"2024-03-06T18:04:51.718008Z","shell.execute_reply.started":"2024-03-06T18:04:51.700295Z"},"trusted":true},"outputs":[],"source":["performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")\n","performance_df1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:51.721029Z","iopub.status.busy":"2024-03-06T18:04:51.720506Z","iopub.status.idle":"2024-03-06T18:04:52.24084Z","shell.execute_reply":"2024-03-06T18:04:52.239432Z","shell.execute_reply.started":"2024-03-06T18:04:51.720983Z"},"trusted":true},"outputs":[],"source":["sns.catplot(x = 'Algorithm', y='value', \n","               hue = 'variable',data=performance_df1, kind='bar',height=5)\n","plt.ylim(0.5,1.0)\n","plt.xticks(rotation='vertical')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["![Confusioin Matrix](https://miro.medium.com/v2/resize:fit:640/format:webp/1*7EYylA6XlXSGBCF77j_rOA.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:52.2431Z","iopub.status.busy":"2024-03-06T18:04:52.242447Z","iopub.status.idle":"2024-03-06T18:04:52.248831Z","shell.execute_reply":"2024-03-06T18:04:52.24753Z","shell.execute_reply.started":"2024-03-06T18:04:52.243061Z"},"trusted":true},"outputs":[],"source":["#In this problem our is to classify the sms is spam or not in given context our best metric would be precision score (it can show the spam mails are classified properly or not) and than accuracy score \n","#so for KNN and the Multinominal Navibayes the Precision are good\n","#But for the accuracy Multinomial navie Bayes is giving best accuracy so we will consider the multinominal classifier"]},{"cell_type":"markdown","metadata":{},"source":["# Make Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:52.251059Z","iopub.status.busy":"2024-03-06T18:04:52.250569Z","iopub.status.idle":"2024-03-06T18:04:52.274013Z","shell.execute_reply":"2024-03-06T18:04:52.272804Z","shell.execute_reply.started":"2024-03-06T18:04:52.251021Z"},"trusted":true},"outputs":[],"source":["#Data Preprocessing ---> Vectorization(tfidf with max features 3000) ----> model(multinomial navie bayes)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:52.2758Z","iopub.status.busy":"2024-03-06T18:04:52.275426Z","iopub.status.idle":"2024-03-06T18:04:52.282649Z","shell.execute_reply":"2024-03-06T18:04:52.281456Z","shell.execute_reply.started":"2024-03-06T18:04:52.275754Z"},"trusted":true},"outputs":[],"source":["X = df['tranformed_text']\n","y = df['target']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:52.28525Z","iopub.status.busy":"2024-03-06T18:04:52.284812Z","iopub.status.idle":"2024-03-06T18:04:52.582384Z","shell.execute_reply":"2024-03-06T18:04:52.58133Z","shell.execute_reply.started":"2024-03-06T18:04:52.28521Z"},"trusted":true},"outputs":[],"source":["tfidf = TfidfVectorizer(max_features = 3000) #our model is giving best accuracy for 3000 features and the precision stays 1\n","X_tf = tfidf.fit_transform(df['tranformed_text']).toarray() #we convert into array cause we get the output in sparse array\n","X_train_tf, X_test_tf, y_train_tf, y_test_tf= train_test_split(X_tf, y, test_size =0.2, random_state = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:52.585376Z","iopub.status.busy":"2024-03-06T18:04:52.585021Z","iopub.status.idle":"2024-03-06T18:04:52.636333Z","shell.execute_reply":"2024-03-06T18:04:52.63502Z","shell.execute_reply.started":"2024-03-06T18:04:52.585346Z"},"trusted":true},"outputs":[],"source":["mnb = MultinomialNB()\n","mnb.fit(X_train_tf, y_train_tf)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:04:52.638965Z","iopub.status.busy":"2024-03-06T18:04:52.638374Z","iopub.status.idle":"2024-03-06T18:04:52.648033Z","shell.execute_reply":"2024-03-06T18:04:52.646746Z","shell.execute_reply.started":"2024-03-06T18:04:52.638926Z"},"trusted":true},"outputs":[],"source":["def predict(X_pred):\n","    X_pred = tranform_text(X_pred)\n","    X_pred = [X_pred] \n","    X_tf = tfidf.transform(X_pred).toarray()  # Use transform instead of fit_transform\n","    predictions = mnb.predict(X_tf)\n","    if predictions == 1:\n","        print(\"The Message is Spam\")\n","    else:\n","        print(\"The Message is not spam\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-06T18:05:12.70816Z","iopub.status.busy":"2024-03-06T18:05:12.707726Z","iopub.status.idle":"2024-03-06T18:05:18.169344Z","shell.execute_reply":"2024-03-06T18:05:18.168239Z","shell.execute_reply.started":"2024-03-06T18:05:12.708126Z"},"trusted":true},"outputs":[],"source":["X_pred = input('Enter the Message: ')\n","predict(X_pred)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":483,"sourceId":982,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
